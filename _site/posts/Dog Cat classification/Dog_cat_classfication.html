<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Haoran Jia">
<meta name="dcterms.date" content="2023-11-03">

<title>myblog - Dog Cat Classfication with Tensorflow</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">myblog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Dog Cat Classfication with Tensorflow</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Haoran Jia </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 3, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="3">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#data-preparation" id="toc-data-preparation" class="nav-link active" data-scroll-target="#data-preparation">Data Preparation</a></li>
  <li><a href="#some-helper-functions" id="toc-some-helper-functions" class="nav-link" data-scroll-target="#some-helper-functions">Some Helper Functions</a></li>
  <li><a href="#modeling" id="toc-modeling" class="nav-link" data-scroll-target="#modeling">Modeling</a>
  <ul class="collapse">
  <li><a href="#simple-cnn-model" id="toc-simple-cnn-model" class="nav-link" data-scroll-target="#simple-cnn-model">1. Simple CNN Model</a></li>
  <li><a href="#model-with-data-augmentation" id="toc-model-with-data-augmentation" class="nav-link" data-scroll-target="#model-with-data-augmentation">2. Model with Data Augmentation</a></li>
  <li><a href="#model-with-data-preprocessing" id="toc-model-with-data-preprocessing" class="nav-link" data-scroll-target="#model-with-data-preprocessing">3. Model with Data Preprocessing</a></li>
  <li><a href="#model-with-tansfer-learning" id="toc-model-with-tansfer-learning" class="nav-link" data-scroll-target="#model-with-tansfer-learning">4. Model with Tansfer Learning</a></li>
  </ul></li>
  <li><a href="#evaluate-best-model-on-testset" id="toc-evaluate-best-model-on-testset" class="nav-link" data-scroll-target="#evaluate-best-model-on-testset">Evaluate Best Model on Testset</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p><strong>Can you distinguish between pictures of dogs and pictures of cats using machine learning algorithms?</strong></p>
<p>In this blog, we will be using Tensorflow to build several neural network models to classify dogs and cats. In this tutorial, you will be familiarized with image data augmentation, preprocessing, and the concept of transfer learning. It is strongly recommended to use colab or any other cloud services to access GPUs for faster training.<br>
<img src="https://www.boredpanda.com/blog/wp-content/uploads/2017/09/funny-cats-vs-dogs-comics-200-59c380533523b__700.jpg" class="img-fluid"></p>
<section id="data-preparation" class="level2">
<h2 class="anchored" data-anchor-id="data-preparation">Data Preparation</h2>
<p>Letâ€™s start with the data import. We will be using a labeled dataset provided by Tensorflow, and we can retrive it from a url.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># package import</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> utils</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="ec752072-d5cb-40d0-93d7-ebc5bd140d1b" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># location of data</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>_URL <span class="op">=</span> <span class="st">'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># download the data and extract it</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>path_to_zip <span class="op">=</span> utils.get_file(<span class="st">'cats_and_dogs.zip'</span>, origin<span class="op">=</span>_URL, extract<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># construct paths</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>PATH <span class="op">=</span> os.path.join(os.path.dirname(path_to_zip), <span class="st">'cats_and_dogs_filtered'</span>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>train_dir <span class="op">=</span> os.path.join(PATH, <span class="st">'train'</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>validation_dir <span class="op">=</span> os.path.join(PATH, <span class="st">'validation'</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co"># parameters for datasets</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>IMG_SIZE <span class="op">=</span> (<span class="dv">160</span>, <span class="dv">160</span>)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="co"># construct train and validation datasets</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> utils.image_dataset_from_directory(train_dir,</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>                          shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>                          batch_size<span class="op">=</span>BATCH_SIZE,</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>                          image_size<span class="op">=</span>IMG_SIZE)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>validation_dataset <span class="op">=</span> utils.image_dataset_from_directory(validation_dir,</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>                            shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>                            batch_size<span class="op">=</span>BATCH_SIZE,</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>                            image_size<span class="op">=</span>IMG_SIZE)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a><span class="co"># construct the test dataset by taking every 5th observation out of the validation dataset</span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>val_batches <span class="op">=</span> tf.data.experimental.cardinality(validation_dataset)</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> validation_dataset.take(val_batches <span class="op">//</span> <span class="dv">5</span>)</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>validation_dataset <span class="op">=</span> validation_dataset.skip(val_batches <span class="op">//</span> <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Found 2000 files belonging to 2 classes.
Found 1000 files belonging to 2 classes.</code></pre>
</div>
</div>
<p>By running this code, we have created TensorFlow Datasets instances for training, validation, and testing. The data will be feeded to the machine learning in batches, and this avoids the need to load all the data into memory.</p>
<p>In our case, we used a special-purpose keras utility called <code>image_dataset_from_directory</code> to construct a Dataset. The first arguments specifies the directory of the dataset. The <code>shuffle</code> argument says that, when retrieving data from this directory, the order should be randomized. The <code>batch_size</code> determines how many data points are gathered from the directory at once. Here, for example, each time we request some data we will get 32 images from each of the data sets. Finally, the <code>image_size</code> specifies the size of the input images.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>AUTOTUNE <span class="op">=</span> tf.data.AUTOTUNE</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> train_dataset.prefetch(buffer_size<span class="op">=</span>AUTOTUNE)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>validation_dataset <span class="op">=</span> validation_dataset.prefetch(buffer_size<span class="op">=</span>AUTOTUNE)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> test_dataset.prefetch(buffer_size<span class="op">=</span>AUTOTUNE)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This is technical code related to rapidly reading data. <a href="https://www.tensorflow.org/guide/data_performance">Here for more</a></p>
<p>We will be using <code>take</code> method to interact with the dataset. For example, <code>train_dataset.take(1)</code> will retrieve one batch (32 images with labels) from the training data. We can write a simple function to visualize some random pictures in the dataset.</p>
<div class="cell" data-outputid="ea8c79d0-cedd-4848-d458-a64bb9daf4e8" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> show_random_pictures(train_dataset, class_names):</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    cat_images <span class="op">=</span> []</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    dog_images <span class="op">=</span> []</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Take 1 batches to ensure we get at least 3 of each class</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> images, labels <span class="kw">in</span> train_dataset.take(<span class="dv">1</span>):</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(labels)):</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Class 0 for Cat, Class 1 for Dog</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> labels[i] <span class="op">==</span> <span class="dv">0</span> <span class="kw">and</span> <span class="bu">len</span>(cat_images) <span class="op">&lt;</span> <span class="dv">3</span>:</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>                cat_images.append(images[i].numpy().astype(<span class="st">"uint8"</span>))</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> labels[i] <span class="op">==</span> <span class="dv">1</span> <span class="kw">and</span> <span class="bu">len</span>(dog_images) <span class="op">&lt;</span> <span class="dv">3</span>:</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>                dog_images.append(images[i].numpy().astype(<span class="st">"uint8"</span>))</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">len</span>(cat_images) <span class="op">==</span> <span class="dv">3</span> <span class="kw">and</span> <span class="bu">len</span>(dog_images) <span class="op">==</span> <span class="dv">3</span>:</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(cat_images) <span class="op">==</span> <span class="dv">3</span> <span class="kw">and</span> <span class="bu">len</span>(dog_images) <span class="op">==</span> <span class="dv">3</span>:</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check if we found enough images</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(cat_images) <span class="op">&lt;</span> <span class="dv">3</span> <span class="kw">or</span> <span class="bu">len</span>(dog_images) <span class="op">&lt;</span> <span class="dv">3</span>:</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Not enough cat or dog images found in the batches taken."</span>)</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plotting Cats</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>        plt.subplot(<span class="dv">2</span>, <span class="dv">3</span>, i<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>        plt.imshow(cat_images[i])</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>        plt.title(class_names[<span class="dv">0</span>])</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>        plt.axis(<span class="st">'off'</span>)</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plotting Dogs</span></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>        plt.subplot(<span class="dv">2</span>, <span class="dv">3</span>, i<span class="op">+</span><span class="dv">4</span>)</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>        plt.imshow(dog_images[i])</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>        plt.title(class_names[<span class="dv">1</span>])</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>        plt.axis(<span class="st">'off'</span>)</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>class_names <span class="op">=</span> [<span class="st">'Cat'</span>, <span class="st">'Dog'</span>] <span class="co"># specify class names</span></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>show_random_pictures(train_dataset, class_names)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Dog_cat_classfication_files/figure-html/cell-5-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> counter(labels_iterator):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize counters for both labels</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    count_label_0 <span class="op">=</span> <span class="dv">0</span>  <span class="co"># for cat</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    count_label_1 <span class="op">=</span> <span class="dv">0</span>  <span class="co"># for dog</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> label <span class="kw">in</span> labels_iterator:</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> label <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>            count_label_0 <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> label <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>            count_label_1 <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Print out the counts</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Number of cat images: </span><span class="sc">{</span>count_label_0<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Number of dog images: </span><span class="sc">{</span>count_label_1<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="221fae5b-a611-4df7-e3d5-b925c5d9de32" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The following line of code will create an iterator to iterate through the dataset</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>labels_iterator<span class="op">=</span> train_dataset.unbatch().<span class="bu">map</span>(<span class="kw">lambda</span> image, label: label).as_numpy_iterator()</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>counter(labels_iterator)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of cat images: 1000
Number of dog images: 1000</code></pre>
</div>
</div>
<p>Since random guess will get 50% accuracy, we will treat this as the benchmark for improvement. Our models should do much better than a 50% baseline.</p>
</section>
<section id="some-helper-functions" class="level2">
<h2 class="anchored" data-anchor-id="some-helper-functions">Some Helper Functions</h2>
<p>For convenience, we will create two helper functions to help us generalize the training of different models and the visualization of results.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to compile and train a model using training and validation datasets.</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compile_and_train(model, train_dataset, validation_dataset):</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compiling the model with 'adam' optimizer, loss function for multiclass classification, </span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># and setting 'accuracy' as the metric for evaluation.</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>,</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>                  loss<span class="op">=</span>tf.keras.losses.SparseCategoricalCrossentropy(from_logits<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>                  metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Training the model on the training dataset for 20 epochs</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># and validating it on validation dataset.</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    history <span class="op">=</span> model.fit(</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>        train_dataset,</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>        epochs<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>        validation_data<span class="op">=</span>validation_dataset</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Returning the history object containing details of training and validation performance.</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> history</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to visualize the training and validation accuracy over epochs.</span></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_training_history(history):</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extracting accuracy metrics from the training history.</span></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>    acc <span class="op">=</span> history.history[<span class="st">'accuracy'</span>]</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>    val_acc <span class="op">=</span> history.history[<span class="st">'val_accuracy'</span>]</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Setting up the range of epochs for plotting.</span></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>    epochs_range <span class="op">=</span> <span class="bu">range</span>(<span class="dv">20</span>)</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initializing a plot with a specific size.</span></span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">4</span>))</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plotting the training accuracy and validation accuracy over epochs.</span></span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>    plt.plot(epochs_range, acc, label<span class="op">=</span><span class="st">'Training Accuracy'</span>)</span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>    plt.plot(epochs_range, val_acc, label<span class="op">=</span><span class="st">'Validation Accuracy'</span>)</span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Adding legend to the plot in the lower right position.</span></span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>    plt.legend(loc<span class="op">=</span><span class="st">'lower right'</span>)</span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Adding a title to the plot.</span></span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Training and Validation Accuracy'</span>)</span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Displaying the plot.</span></span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="modeling" class="level2">
<h2 class="anchored" data-anchor-id="modeling">Modeling</h2>
<section id="simple-cnn-model" class="level3">
<h3 class="anchored" data-anchor-id="simple-cnn-model">1. Simple CNN Model</h3>
<p>We can start with a simple convolutional neural network model with three convolutional blocks and one classifier. The task is binary classification so we would define the last layer as <code>tf.keras.layers.Dense(2)</code> with two output neurons. <code>tf.keras.layers.BatchNormalization()</code> applies batch normalization to the inputs, which is a technique used to improve the performance and stability of the model.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the model</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>model1 <span class="op">=</span> tf.keras.Sequential([</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># First Convolutional Block</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>, input_shape<span class="op">=</span>(IMG_SIZE[<span class="dv">0</span>], IMG_SIZE[<span class="dv">1</span>], <span class="dv">3</span>)),</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.BatchNormalization(),</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Dropout(<span class="fl">0.25</span>),</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Second Convolutional Block</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.BatchNormalization(),</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Dropout(<span class="fl">0.25</span>),</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Third Convolutional Block</span></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Conv2D(<span class="dv">128</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Conv2D(<span class="dv">128</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.BatchNormalization(),</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Dropout(<span class="fl">0.25</span>),</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Classifier</span></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Flatten(),</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Dense(<span class="dv">512</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.BatchNormalization(),</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Dropout(<span class="fl">0.5</span>),</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Dense(<span class="dv">2</span>)</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="df4bee01-2ccb-4d9e-b04c-8cf01b2b22d7" data-execution_count="10">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>history1 <span class="op">=</span> compile_and_train(model1, train_dataset, validation_dataset)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20
63/63 [==============================] - 32s 154ms/step - loss: 1.2226 - accuracy: 0.5705 - val_loss: 3.6936 - val_accuracy: 0.5087
Epoch 2/20
63/63 [==============================] - 8s 122ms/step - loss: 0.9374 - accuracy: 0.5825 - val_loss: 0.7353 - val_accuracy: 0.6027
Epoch 3/20
63/63 [==============================] - 8s 127ms/step - loss: 0.7614 - accuracy: 0.6440 - val_loss: 0.7294 - val_accuracy: 0.6015
Epoch 4/20
63/63 [==============================] - 8s 128ms/step - loss: 0.6735 - accuracy: 0.6870 - val_loss: 0.8700 - val_accuracy: 0.5804
Epoch 5/20
63/63 [==============================] - 8s 122ms/step - loss: 0.5658 - accuracy: 0.7295 - val_loss: 0.7950 - val_accuracy: 0.5792
Epoch 6/20
63/63 [==============================] - 9s 133ms/step - loss: 0.4795 - accuracy: 0.7855 - val_loss: 0.8196 - val_accuracy: 0.6423
Epoch 7/20
63/63 [==============================] - 9s 136ms/step - loss: 0.4845 - accuracy: 0.7840 - val_loss: 0.7983 - val_accuracy: 0.6163
Epoch 8/20
63/63 [==============================] - 8s 122ms/step - loss: 0.3717 - accuracy: 0.8355 - val_loss: 1.0909 - val_accuracy: 0.6089
Epoch 9/20
63/63 [==============================] - 8s 128ms/step - loss: 0.3083 - accuracy: 0.8635 - val_loss: 0.7620 - val_accuracy: 0.6634
Epoch 10/20
63/63 [==============================] - 10s 149ms/step - loss: 0.2690 - accuracy: 0.8860 - val_loss: 0.7754 - val_accuracy: 0.6894
Epoch 11/20
63/63 [==============================] - 8s 122ms/step - loss: 0.2564 - accuracy: 0.8965 - val_loss: 0.7915 - val_accuracy: 0.6980
Epoch 12/20
63/63 [==============================] - 8s 128ms/step - loss: 0.1821 - accuracy: 0.9245 - val_loss: 0.8409 - val_accuracy: 0.6770
Epoch 13/20
63/63 [==============================] - 8s 125ms/step - loss: 0.1559 - accuracy: 0.9400 - val_loss: 0.8358 - val_accuracy: 0.7129
Epoch 14/20
63/63 [==============================] - 8s 125ms/step - loss: 0.1368 - accuracy: 0.9505 - val_loss: 0.8645 - val_accuracy: 0.6918
Epoch 15/20
63/63 [==============================] - 8s 127ms/step - loss: 0.1086 - accuracy: 0.9605 - val_loss: 0.8438 - val_accuracy: 0.7351
Epoch 16/20
63/63 [==============================] - 8s 123ms/step - loss: 0.1015 - accuracy: 0.9650 - val_loss: 0.9680 - val_accuracy: 0.6980
Epoch 17/20
63/63 [==============================] - 9s 129ms/step - loss: 0.1015 - accuracy: 0.9605 - val_loss: 0.9604 - val_accuracy: 0.6943
Epoch 18/20
63/63 [==============================] - 8s 127ms/step - loss: 0.0850 - accuracy: 0.9675 - val_loss: 1.1079 - val_accuracy: 0.6881
Epoch 19/20
63/63 [==============================] - 8s 128ms/step - loss: 0.0867 - accuracy: 0.9680 - val_loss: 1.0985 - val_accuracy: 0.7042
Epoch 20/20
63/63 [==============================] - 8s 125ms/step - loss: 0.0789 - accuracy: 0.9685 - val_loss: 1.2521 - val_accuracy: 0.6881</code></pre>
</div>
</div>
<div class="cell" data-outputid="78753b3d-ff3b-4279-e2e4-94380504a064" data-execution_count="12">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>plot_training_history(history1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Dog_cat_classfication_files/figure-html/cell-11-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><strong>As we can observe, the training accuracy goes all the way up to 0.97, while the validation accuracy fluctuates around 0.68.</strong> This is a clear signal of overfitting. But there is at least a 0.18 improvement over the baseline.</p>
</section>
<section id="model-with-data-augmentation" class="level3">
<h3 class="anchored" data-anchor-id="model-with-data-augmentation">2. Model with Data Augmentation</h3>
<p>Now we are going to add some data augmentation layers to the model. Data augmentation refers to the practice of including modified copies of the same image in the training set. For example, a picture of a cat is still a picture of a cat even if we flip it upside down or rotate it 90 degrees. We can include such transformed versions of the image in our training process in order to help our model learn so-called invariant features of our input images. We will start by looking at the actual examples of flipping and rotation.</p>
<section id="randomflip-augmentation" class="level4">
<h4 class="anchored" data-anchor-id="randomflip-augmentation">RandomFlip Augmentation</h4>
<div class="cell" data-outputid="336becc5-227e-4666-ffa5-f719cef3f026" data-execution_count="14">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> visualize_random_flip(image):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    random_flip_layer <span class="op">=</span> tf.keras.layers.RandomFlip(<span class="st">"horizontal_and_vertical"</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    plt.imshow(image.numpy().astype(<span class="st">"uint8"</span>))</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Original image'</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Apply the RandomFlip layer to the same image several times</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">8</span>):</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>        plt.subplot(<span class="dv">3</span>, <span class="dv">3</span>, i<span class="op">+</span><span class="dv">2</span>)</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>        flipped_image <span class="op">=</span> random_flip_layer(image, training<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>        plt.imshow(flipped_image.numpy().astype(<span class="st">"uint8"</span>))</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="ss">f'Flipped image </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>        plt.axis(<span class="st">'off'</span>)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Retrieve a batch of images from the training dataset and visualize the first one</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> images, _ <span class="kw">in</span> train_dataset.take(<span class="dv">1</span>):</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>    visualize_random_flip(images[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Dog_cat_classfication_files/figure-html/cell-12-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="randomrotation-augmentation" class="level4">
<h4 class="anchored" data-anchor-id="randomrotation-augmentation">RandomRotation Augmentation</h4>
<div class="cell" data-outputid="9042143c-1eda-41f6-c694-c785a8f90b1a" data-execution_count="15">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> visualize_random_rotation(image):</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    random_rotation_layer <span class="op">=</span> tf.keras.layers.RandomRotation(<span class="fl">0.2</span>)  <span class="co"># 20% of 360 degrees</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    plt.imshow(image.numpy().astype(<span class="st">"uint8"</span>))</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Original image'</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Apply the RandomRotation layer to the same image several times</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">8</span>):</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>        plt.subplot(<span class="dv">3</span>, <span class="dv">3</span>, i<span class="op">+</span><span class="dv">2</span>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>        rotated_image <span class="op">=</span> random_rotation_layer(image, training<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>        plt.imshow(rotated_image.numpy().astype(<span class="st">"uint8"</span>))</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="ss">f'Rotated image </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>        plt.axis(<span class="st">'off'</span>)</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize the first one</span></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>visualize_random_rotation(images[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Dog_cat_classfication_files/figure-html/cell-13-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="build-a-model-with-data-augmentation" class="level4">
<h4 class="anchored" data-anchor-id="build-a-model-with-data-augmentation">Build a Model with Data Augmentation</h4>
<p>Now we are creating a new model called <code>model2</code> in which the first two layers are augmentation layers, while other layers remain similar to model1.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the Sequential model</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>model2 <span class="op">=</span> tf.keras.Sequential([</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Data Augmentation Block</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.RandomFlip(<span class="st">"horizontal"</span>),</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.RandomRotation(<span class="fl">0.2</span>),</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># First Convolutional Block</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>, input_shape<span class="op">=</span>(IMG_SIZE[<span class="dv">0</span>], IMG_SIZE[<span class="dv">1</span>], <span class="dv">3</span>)),</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.BatchNormalization(),</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Dropout(<span class="fl">0.25</span>),</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Second Convolutional Block</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.BatchNormalization(),</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Dropout(<span class="fl">0.25</span>),</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Third Convolutional Block</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Conv2D(<span class="dv">128</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Conv2D(<span class="dv">128</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.BatchNormalization(),</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Dropout(<span class="fl">0.25</span>),</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Classifier</span></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Flatten(),</span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Dense(<span class="dv">512</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.BatchNormalization(),</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Dropout(<span class="fl">0.5</span>),</span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Dense(<span class="dv">2</span>)</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="train-and-visualize-the-result" class="level4">
<h4 class="anchored" data-anchor-id="train-and-visualize-the-result">Train and Visualize the Result</h4>
<div class="cell" data-outputid="d0825808-d593-4f1c-cb42-59c19a2ed7ae" data-execution_count="17">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>history2 <span class="op">=</span> compile_and_train(model2, train_dataset, validation_dataset)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20
63/63 [==============================] - 13s 127ms/step - loss: 1.2798 - accuracy: 0.5445 - val_loss: 3.9599 - val_accuracy: 0.4802
Epoch 2/20
63/63 [==============================] - 8s 130ms/step - loss: 0.9775 - accuracy: 0.5725 - val_loss: 0.8683 - val_accuracy: 0.5656
Epoch 3/20
63/63 [==============================] - 9s 139ms/step - loss: 0.8225 - accuracy: 0.6055 - val_loss: 0.6811 - val_accuracy: 0.6188
Epoch 4/20
63/63 [==============================] - 9s 129ms/step - loss: 0.7024 - accuracy: 0.6385 - val_loss: 0.6933 - val_accuracy: 0.6312
Epoch 5/20
63/63 [==============================] - 9s 139ms/step - loss: 0.6925 - accuracy: 0.6445 - val_loss: 0.6573 - val_accuracy: 0.6151
Epoch 6/20
63/63 [==============================] - 8s 126ms/step - loss: 0.6302 - accuracy: 0.6770 - val_loss: 0.6138 - val_accuracy: 0.6770
Epoch 7/20
63/63 [==============================] - 9s 133ms/step - loss: 0.6284 - accuracy: 0.6745 - val_loss: 0.6516 - val_accuracy: 0.6658
Epoch 8/20
63/63 [==============================] - 10s 148ms/step - loss: 0.5832 - accuracy: 0.7135 - val_loss: 0.5679 - val_accuracy: 0.6955
Epoch 9/20
63/63 [==============================] - 8s 123ms/step - loss: 0.5760 - accuracy: 0.7070 - val_loss: 0.8166 - val_accuracy: 0.6275
Epoch 10/20
63/63 [==============================] - 9s 131ms/step - loss: 0.5764 - accuracy: 0.7155 - val_loss: 0.5684 - val_accuracy: 0.7054
Epoch 11/20
63/63 [==============================] - 9s 133ms/step - loss: 0.5581 - accuracy: 0.7175 - val_loss: 0.6261 - val_accuracy: 0.6448
Epoch 12/20
63/63 [==============================] - 8s 126ms/step - loss: 0.5315 - accuracy: 0.7420 - val_loss: 0.6335 - val_accuracy: 0.6535
Epoch 13/20
63/63 [==============================] - 8s 128ms/step - loss: 0.5376 - accuracy: 0.7365 - val_loss: 0.5897 - val_accuracy: 0.7104
Epoch 14/20
63/63 [==============================] - 8s 130ms/step - loss: 0.5376 - accuracy: 0.7295 - val_loss: 0.8979 - val_accuracy: 0.6077
Epoch 15/20
63/63 [==============================] - 8s 129ms/step - loss: 0.5391 - accuracy: 0.7385 - val_loss: 0.6124 - val_accuracy: 0.6955
Epoch 16/20
63/63 [==============================] - 9s 128ms/step - loss: 0.5107 - accuracy: 0.7595 - val_loss: 0.6661 - val_accuracy: 0.6498
Epoch 17/20
63/63 [==============================] - 9s 140ms/step - loss: 0.5144 - accuracy: 0.7420 - val_loss: 0.5801 - val_accuracy: 0.7240
Epoch 18/20
63/63 [==============================] - 8s 123ms/step - loss: 0.4859 - accuracy: 0.7755 - val_loss: 0.5417 - val_accuracy: 0.7401
Epoch 19/20
63/63 [==============================] - 8s 129ms/step - loss: 0.4973 - accuracy: 0.7630 - val_loss: 0.6247 - val_accuracy: 0.6943
Epoch 20/20
63/63 [==============================] - 9s 148ms/step - loss: 0.4820 - accuracy: 0.7625 - val_loss: 0.5458 - val_accuracy: 0.7228</code></pre>
</div>
</div>
<div class="cell" data-outputid="fcbb7412-de3d-4cd7-8277-47f508c865d8" data-execution_count="18">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>plot_training_history(history2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Dog_cat_classfication_files/figure-html/cell-16-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><strong>As we can observe, the training accuracy goes to 0.77, about 0.2 lower than model1, but the validation accuracy becomes higher than before, reaching a maximum of 0.74.</strong> This shows that data augmentation has helped us balance the bias of the model, but the model is still not sufficient to make accuracy predictions, though it is 24% higher in accuracy than random guess.</p>
</section>
</section>
<section id="model-with-data-preprocessing" class="level3">
<h3 class="anchored" data-anchor-id="model-with-data-preprocessing">3. Model with Data Preprocessing</h3>
<p>Sometimes, it can be helpful to make simple transformations to the input data. For example, in this case, the original data has pixels with RGB values between 0 and 255, but many models will train faster with RGB values normalized between 0 and 1, or possibly between -1 and 1. These are mathematically identical situations, since we can always just scale the weights. But if we handle the scaling prior to the training process, we can spend more of our training energy handling actual signal in the data and less energy having the weights adjust to the data scale.</p>
<p>In the following section, we will define a function to create a preprocessor for the input, and incoporate this into our model.</p>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the preprocessor as the first layer of the model</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_preprocessor():</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> tf.keras.Input(shape<span class="op">=</span>(<span class="dv">160</span>, <span class="dv">160</span>, <span class="dv">3</span>))</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> tf.keras.applications.mobilenet_v2.preprocess_input(i)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    preprocessor <span class="op">=</span> tf.keras.Model(inputs<span class="op">=</span>[i], outputs<span class="op">=</span>[x])</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> preprocessor</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the model with the preprocessor layer, data augmentation, and the rest of the architecture</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_model3():</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    preprocessor <span class="op">=</span> create_preprocessor()</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> tf.keras.Sequential([</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>        preprocessor,</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.RandomFlip(<span class="st">"horizontal"</span>),</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.RandomRotation(<span class="fl">0.1</span>),</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># First Convolutional Block</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>, input_shape<span class="op">=</span>(IMG_SIZE[<span class="dv">0</span>], IMG_SIZE[<span class="dv">1</span>], <span class="dv">3</span>)),</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.BatchNormalization(),</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.Dropout(<span class="fl">0.25</span>),</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Second Convolutional Block</span></span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.BatchNormalization(),</span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.Dropout(<span class="fl">0.25</span>),</span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Third Convolutional Block</span></span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.Conv2D(<span class="dv">128</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.Conv2D(<span class="dv">128</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.BatchNormalization(),</span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.Dropout(<span class="fl">0.25</span>),</span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Classifier</span></span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.Flatten(),</span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.Dense(<span class="dv">512</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.BatchNormalization(),</span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.Dropout(<span class="fl">0.5</span>),</span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.Dense(<span class="dv">2</span>)</span>
<span id="cb20-43"><a href="#cb20-43" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb20-44"><a href="#cb20-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="57db23ef-dd0d-45cc-a116-2b37b10c1b7a" data-execution_count="42">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Build model, train, and visualize the result</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>model3 <span class="op">=</span> create_model3()</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>history3 <span class="op">=</span> compile_and_train(model3, train_dataset, validation_dataset)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>plot_training_history(history3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20
63/63 [==============================] - 13s 154ms/step - loss: 1.2568 - accuracy: 0.5475 - val_loss: 2.8958 - val_accuracy: 0.4950
Epoch 2/20
63/63 [==============================] - 8s 122ms/step - loss: 0.8847 - accuracy: 0.6115 - val_loss: 0.8993 - val_accuracy: 0.5087
Epoch 3/20
63/63 [==============================] - 9s 133ms/step - loss: 0.7476 - accuracy: 0.6495 - val_loss: 2.0710 - val_accuracy: 0.4839
Epoch 4/20
63/63 [==============================] - 10s 150ms/step - loss: 0.6810 - accuracy: 0.6555 - val_loss: 2.4050 - val_accuracy: 0.4950
Epoch 5/20
63/63 [==============================] - 8s 124ms/step - loss: 0.6590 - accuracy: 0.6835 - val_loss: 1.4140 - val_accuracy: 0.5025
Epoch 6/20
63/63 [==============================] - 10s 150ms/step - loss: 0.6129 - accuracy: 0.6980 - val_loss: 1.4951 - val_accuracy: 0.5483
Epoch 7/20
63/63 [==============================] - 10s 148ms/step - loss: 0.5817 - accuracy: 0.7125 - val_loss: 1.1408 - val_accuracy: 0.5582
Epoch 8/20
63/63 [==============================] - 8s 123ms/step - loss: 0.5568 - accuracy: 0.7370 - val_loss: 0.7060 - val_accuracy: 0.6782
Epoch 9/20
63/63 [==============================] - 8s 127ms/step - loss: 0.5054 - accuracy: 0.7525 - val_loss: 0.6921 - val_accuracy: 0.6547
Epoch 10/20
63/63 [==============================] - 10s 151ms/step - loss: 0.5229 - accuracy: 0.7615 - val_loss: 0.7175 - val_accuracy: 0.6559
Epoch 11/20
63/63 [==============================] - 8s 123ms/step - loss: 0.5293 - accuracy: 0.7420 - val_loss: 0.6566 - val_accuracy: 0.6955
Epoch 12/20
63/63 [==============================] - 8s 131ms/step - loss: 0.4943 - accuracy: 0.7600 - val_loss: 0.5879 - val_accuracy: 0.7240
Epoch 13/20
63/63 [==============================] - 9s 139ms/step - loss: 0.4684 - accuracy: 0.7895 - val_loss: 0.5879 - val_accuracy: 0.7116
Epoch 14/20
63/63 [==============================] - 8s 124ms/step - loss: 0.4616 - accuracy: 0.7850 - val_loss: 0.7305 - val_accuracy: 0.6733
Epoch 15/20
63/63 [==============================] - 8s 129ms/step - loss: 0.4520 - accuracy: 0.7845 - val_loss: 0.7629 - val_accuracy: 0.6436
Epoch 16/20
63/63 [==============================] - 10s 150ms/step - loss: 0.4314 - accuracy: 0.7950 - val_loss: 0.5917 - val_accuracy: 0.7438
Epoch 17/20
63/63 [==============================] - 8s 123ms/step - loss: 0.4302 - accuracy: 0.7990 - val_loss: 0.5291 - val_accuracy: 0.7611
Epoch 18/20
63/63 [==============================] - 8s 128ms/step - loss: 0.4209 - accuracy: 0.8135 - val_loss: 0.6225 - val_accuracy: 0.7030
Epoch 19/20
63/63 [==============================] - 9s 145ms/step - loss: 0.4149 - accuracy: 0.8135 - val_loss: 0.6208 - val_accuracy: 0.7265
Epoch 20/20
63/63 [==============================] - 10s 141ms/step - loss: 0.4416 - accuracy: 0.7900 - val_loss: 0.6819 - val_accuracy: 0.7215</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="Dog_cat_classfication_files/figure-html/cell-18-output-2.png" class="img-fluid"></p>
</div>
</div>
<p><strong>There is a constant increase in training and validation accuracy, where the training accuracy increases less sharply after reaching 0.78, and validation accuracy fluctuates around 0.7.</strong> Though the training accuracy is still higher than the validation accuracy, the overfitting problem is less severe than the previous two models. As the training going on, the training and validation accuracy increase at the same time.</p>
</section>
<section id="model-with-tansfer-learning" class="level3">
<h3 class="anchored" data-anchor-id="model-with-tansfer-learning">4. Model with Tansfer Learning</h3>
<p>So far we are building everything and train randomized weights from scratch. But the idea of transfer learning allows us to make use of some pretrained models that does a related task. For example, a model that is trained on <code>imagenet</code> could help us locate features in a picture so that we only need to add a classifier and fine-tune the whole model to get the results.</p>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_model4():</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Download and configure the MobileNetV2 base model</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    base_model <span class="op">=</span> tf.keras.applications.MobileNetV2(input_shape<span class="op">=</span>(IMG_SIZE[<span class="dv">0</span>], IMG_SIZE[<span class="dv">1</span>], <span class="dv">3</span>),</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>                                                  include_top<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>                                                  weights<span class="op">=</span><span class="st">'imagenet'</span>)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>    base_model.trainable <span class="op">=</span> <span class="va">False</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define the base_model_layer using the base model</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> tf.keras.Input(shape<span class="op">=</span>(IMG_SIZE[<span class="dv">0</span>], IMG_SIZE[<span class="dv">1</span>], <span class="dv">3</span>))</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> base_model(i, training<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>    base_model_layer <span class="op">=</span> tf.keras.Model(inputs<span class="op">=</span>[i], outputs<span class="op">=</span>[x])</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create the preprocessor layer</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>    preprocessor <span class="op">=</span> create_preprocessor()  <span class="co"># Assuming this function was defined as before</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define the new model using the layers described</span></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>    model4 <span class="op">=</span> tf.keras.Sequential([</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>        preprocessor,</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.RandomFlip(<span class="st">"horizontal_and_vertical"</span>),</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.RandomRotation(<span class="fl">0.2</span>),</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>        base_model_layer,</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.GlobalMaxPooling2D(),</span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.Dropout(<span class="fl">0.2</span>),  <span class="co"># Optional, adjust the rate as needed</span></span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.Dense(<span class="dv">2</span>)  <span class="co"># Output layer with 2 neurons for binary classification</span></span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model4</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="d46d078a-1a82-4dd8-f44d-0dc0ca0286fb" data-execution_count="25">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>model4 <span class="op">=</span> create_model4()</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>history4 <span class="op">=</span> compile_and_train(model4, train_dataset, validation_dataset)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the training history</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>plot_training_history(history4)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20
63/63 [==============================] - 13s 155ms/step - loss: 1.2855 - accuracy: 0.7155 - val_loss: 0.1718 - val_accuracy: 0.9455
Epoch 2/20
63/63 [==============================] - 4s 56ms/step - loss: 0.5989 - accuracy: 0.8450 - val_loss: 0.1537 - val_accuracy: 0.9480
Epoch 3/20
63/63 [==============================] - 4s 56ms/step - loss: 0.5038 - accuracy: 0.8670 - val_loss: 0.1679 - val_accuracy: 0.9480
Epoch 4/20
63/63 [==============================] - 5s 84ms/step - loss: 0.4607 - accuracy: 0.8830 - val_loss: 0.1174 - val_accuracy: 0.9629
Epoch 5/20
63/63 [==============================] - 5s 74ms/step - loss: 0.4095 - accuracy: 0.8925 - val_loss: 0.0826 - val_accuracy: 0.9715
Epoch 6/20
63/63 [==============================] - 5s 81ms/step - loss: 0.3745 - accuracy: 0.8950 - val_loss: 0.1055 - val_accuracy: 0.9567
Epoch 7/20
63/63 [==============================] - 4s 57ms/step - loss: 0.3485 - accuracy: 0.9015 - val_loss: 0.1217 - val_accuracy: 0.9530
Epoch 8/20
63/63 [==============================] - 4s 57ms/step - loss: 0.3826 - accuracy: 0.8980 - val_loss: 0.0818 - val_accuracy: 0.9728
Epoch 9/20
63/63 [==============================] - 6s 91ms/step - loss: 0.3408 - accuracy: 0.9095 - val_loss: 0.1318 - val_accuracy: 0.9567
Epoch 10/20
63/63 [==============================] - 4s 57ms/step - loss: 0.4176 - accuracy: 0.8990 - val_loss: 0.0917 - val_accuracy: 0.9715
Epoch 11/20
63/63 [==============================] - 6s 96ms/step - loss: 0.2995 - accuracy: 0.9120 - val_loss: 0.0858 - val_accuracy: 0.9740
Epoch 12/20
63/63 [==============================] - 4s 57ms/step - loss: 0.3142 - accuracy: 0.9090 - val_loss: 0.0775 - val_accuracy: 0.9790
Epoch 13/20
63/63 [==============================] - 4s 56ms/step - loss: 0.3440 - accuracy: 0.8960 - val_loss: 0.0750 - val_accuracy: 0.9790
Epoch 14/20
63/63 [==============================] - 5s 82ms/step - loss: 0.2690 - accuracy: 0.9095 - val_loss: 0.1389 - val_accuracy: 0.9530
Epoch 15/20
63/63 [==============================] - 4s 56ms/step - loss: 0.2928 - accuracy: 0.9130 - val_loss: 0.0719 - val_accuracy: 0.9728
Epoch 16/20
63/63 [==============================] - 6s 91ms/step - loss: 0.2924 - accuracy: 0.9095 - val_loss: 0.0744 - val_accuracy: 0.9728
Epoch 17/20
63/63 [==============================] - 4s 57ms/step - loss: 0.2639 - accuracy: 0.9130 - val_loss: 0.0727 - val_accuracy: 0.9703
Epoch 18/20
63/63 [==============================] - 5s 70ms/step - loss: 0.2810 - accuracy: 0.9060 - val_loss: 0.0773 - val_accuracy: 0.9728
Epoch 19/20
63/63 [==============================] - 4s 60ms/step - loss: 0.2505 - accuracy: 0.9185 - val_loss: 0.0974 - val_accuracy: 0.9703
Epoch 20/20
63/63 [==============================] - 4s 57ms/step - loss: 0.2911 - accuracy: 0.9160 - val_loss: 0.0816 - val_accuracy: 0.9728</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="Dog_cat_classfication_files/figure-html/cell-20-output-2.png" class="img-fluid"></p>
</div>
</div>
<p><strong>The validation accuracy is consistantly above 0.97, and the training accuracy is around 0.9.</strong> The accuracy is significantly higher than the previous three models, and overfitting is not observed.</p>
<div class="cell" data-outputid="1ed5a6b3-4bdf-4031-b1b3-6522bce747f6" data-execution_count="26">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>model4.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 model_2 (Functional)        (None, 160, 160, 3)       0         
                                                                 
 random_flip_3 (RandomFlip)  (None, 160, 160, 3)       0         
                                                                 
 random_rotation_3 (RandomR  (None, 160, 160, 3)       0         
 otation)                                                        
                                                                 
 model_1 (Functional)        (None, 5, 5, 1280)        2257984   
                                                                 
 global_max_pooling2d (Glob  (None, 1280)              0         
 alMaxPooling2D)                                                 
                                                                 
 dropout_12 (Dropout)        (None, 1280)              0         
                                                                 
 dense_6 (Dense)             (None, 2)                 2562      
                                                                 
=================================================================
Total params: 2260546 (8.62 MB)
Trainable params: 2562 (10.01 KB)
Non-trainable params: 2257984 (8.61 MB)
_________________________________________________________________</code></pre>
</div>
</div>
<p>From the model summary, we can see that most of the parameters are from the pretrined model within the <code>base_model_layer</code>.</p>
</section>
</section>
<section id="evaluate-best-model-on-testset" class="level2">
<h2 class="anchored" data-anchor-id="evaluate-best-model-on-testset">Evaluate Best Model on Testset</h2>
<div class="cell" data-outputid="d10853ab-b6cd-4737-c05b-4998b752154c" data-execution_count="28">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate on test set</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>test_loss, test_accuracy <span class="op">=</span> model4.evaluate(test_dataset)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test Accuracy: </span><span class="sc">{</span>test_accuracy <span class="op">*</span> <span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>6/6 [==============================] - 1s 88ms/step - loss: 0.0464 - accuracy: 0.9740
Test Accuracy: 97.40%</code></pre>
</div>
</div>
<p>As a result, the model gets 97.40% accuracy on the unseen testset.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>